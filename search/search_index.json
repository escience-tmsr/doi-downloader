{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to doi_downloader The scope of doi_downloader is to provide a simple and efficient way to download PDFs from DOIs. It supports multiple sources and can be easily extended with new plugins. Plugins are adaptors to online API services that can provide PDF URLs given a DOI. The library is designed to be easy to use and extend, making it a great choice for researchers and developers who need to download PDFs from DOIs. urrent plugins include: Crossref : A widely used service for retrieving metadata and content associated with DOIs. Unpaywall : A service that provides access to open access versions of scholarly articles. CORE : A service that aggregates open access research outputs from repositories and journals worldwide. SerpApi : A service that provides access to search engine results, including scholarly articles.","title":"Home"},{"location":"#welcome-to-doi_downloader","text":"The scope of doi_downloader is to provide a simple and efficient way to download PDFs from DOIs. It supports multiple sources and can be easily extended with new plugins. Plugins are adaptors to online API services that can provide PDF URLs given a DOI. The library is designed to be easy to use and extend, making it a great choice for researchers and developers who need to download PDFs from DOIs. urrent plugins include: Crossref : A widely used service for retrieving metadata and content associated with DOIs. Unpaywall : A service that provides access to open access versions of scholarly articles. CORE : A service that aggregates open access research outputs from repositories and journals worldwide. SerpApi : A service that provides access to search engine results, including scholarly articles.","title":"Welcome to doi_downloader"},{"location":"configuration/","text":"Configuration Certain plugins might require configuration to work properly. These parameters can be saved in a .env file in the root of your project. test.env shows a test env file. This can be compied to a .env file. Example of a parameter that needs to be set is an email address for the Unpaywall plugin. Develpong new plugins with API key access would also require an API key to be set in the .env file. The environment variables are loaded automatically from the Plugin class interface. Current plugins needing configuration are: Unpaywall : requires UNPAYWALL_EMAIL variable to be set to an email address. Google Scholar : reuires SERPAPI_KEY to be set to a Google Scholar API key. Accessing the env variables from the plugin To use an env variable simply use os.getenv() in the plugin code. For example, if you have an env variable called UNPAYWALL_EMAIL , you can access it like this: import os unpaywall_email = os.getenv('UNPAYWALL_EMAIL')","title":"Configuration"},{"location":"configuration/#configuration","text":"Certain plugins might require configuration to work properly. These parameters can be saved in a .env file in the root of your project. test.env shows a test env file. This can be compied to a .env file. Example of a parameter that needs to be set is an email address for the Unpaywall plugin. Develpong new plugins with API key access would also require an API key to be set in the .env file. The environment variables are loaded automatically from the Plugin class interface. Current plugins needing configuration are: Unpaywall : requires UNPAYWALL_EMAIL variable to be set to an email address. Google Scholar : reuires SERPAPI_KEY to be set to a Google Scholar API key.","title":"Configuration"},{"location":"configuration/#accessing-the-env-variables-from-the-plugin","text":"To use an env variable simply use os.getenv() in the plugin code. For example, if you have an env variable called UNPAYWALL_EMAIL , you can access it like this: import os unpaywall_email = os.getenv('UNPAYWALL_EMAIL')","title":"Accessing the env variables from the plugin"},{"location":"contributing/","text":"Contributing View CONTRIBUTING on GitHub","title":"Contributing"},{"location":"contributing/#contributing","text":"View CONTRIBUTING on GitHub","title":"Contributing"},{"location":"examples/","text":"Examples Using a single plugin In this example we will use the Unpaywall plugin to fetch PDF URLs for a list of DOIs. from doi_downloader import loader as ld plugins = ld.plugins upw = plugins['UnpaywallPlugin'] doi = \"10.1038/s41586-020-2649-2\" pdf_url = upw.get_pdf_url(doi) Reading dois from a CSV file In this example we will read DOIs from a CSV file and use the Unpaywall plugin to fetch PDF URLs for each DOI. from doi_downloader import loader as ld from doi_downloader import csv unique_dois = csv.load_dois_from_file(dois_file_path, \"doi\", unique=True) plugins = ld.plugins upw = plugins['UnpaywallPlugin'] for doi in unique_dois: pdf_url = upw.get_pdf_url(doi, use_cache=True) print(f'{doi}: {pdf_url}') Attempt to download the PDF In this example we will attempt to download the PDF for a list of DOIs using the Unpaywall plugin. from doi_downloader import loader as ld from doi_downloader import csv from doi_downloader import pdf_download as pdf_dl unique_dois = csv.load_dois_from_file(dois_file_path, \"doi\", unique=True) plugins = ld.plugins upw = plugins['UnpaywallPlugin'] for doi in unique_dois: pdf_url = upw.get_pdf_url(doi, use_cache=True) if pdf_url: # Sanitize DOI for filename safe_filename = doi.replace(\"/\", \"_\").replace(\".\", \"_\") + \".pdf\" downloaded_file = pdf_dl.download_pdf(url, safe_filename, output_dir) if downloaded_file: print(f\"Downloaded {doi} to {downloaded_file}\") else: print(f\"Failed to download {doi}\") Using multiple plugins In this example we will use all plugins through a helper function that will attempt to download the PDFs. from doi_downloader import doi_downloader as ddl from doi_downloader import csv dois_file_path = \"dois.csv\" unique_dois = csv.load_dois_from_file(dois_file_path, \"doi\", unique=True) for doi in unique_dois: ddl.download(doi, output_dir=\"downloads\", force_download=True)","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/#using-a-single-plugin","text":"In this example we will use the Unpaywall plugin to fetch PDF URLs for a list of DOIs. from doi_downloader import loader as ld plugins = ld.plugins upw = plugins['UnpaywallPlugin'] doi = \"10.1038/s41586-020-2649-2\" pdf_url = upw.get_pdf_url(doi)","title":"Using a single plugin"},{"location":"examples/#reading-dois-from-a-csv-file","text":"In this example we will read DOIs from a CSV file and use the Unpaywall plugin to fetch PDF URLs for each DOI. from doi_downloader import loader as ld from doi_downloader import csv unique_dois = csv.load_dois_from_file(dois_file_path, \"doi\", unique=True) plugins = ld.plugins upw = plugins['UnpaywallPlugin'] for doi in unique_dois: pdf_url = upw.get_pdf_url(doi, use_cache=True) print(f'{doi}: {pdf_url}')","title":"Reading dois from a CSV file"},{"location":"examples/#attempt-to-download-the-pdf","text":"In this example we will attempt to download the PDF for a list of DOIs using the Unpaywall plugin. from doi_downloader import loader as ld from doi_downloader import csv from doi_downloader import pdf_download as pdf_dl unique_dois = csv.load_dois_from_file(dois_file_path, \"doi\", unique=True) plugins = ld.plugins upw = plugins['UnpaywallPlugin'] for doi in unique_dois: pdf_url = upw.get_pdf_url(doi, use_cache=True) if pdf_url: # Sanitize DOI for filename safe_filename = doi.replace(\"/\", \"_\").replace(\".\", \"_\") + \".pdf\" downloaded_file = pdf_dl.download_pdf(url, safe_filename, output_dir) if downloaded_file: print(f\"Downloaded {doi} to {downloaded_file}\") else: print(f\"Failed to download {doi}\")","title":"Attempt to download the PDF"},{"location":"examples/#using-multiple-plugins","text":"In this example we will use all plugins through a helper function that will attempt to download the PDFs. from doi_downloader import doi_downloader as ddl from doi_downloader import csv dois_file_path = \"dois.csv\" unique_dois = csv.load_dois_from_file(dois_file_path, \"doi\", unique=True) for doi in unique_dois: ddl.download(doi, output_dir=\"downloads\", force_download=True)","title":"Using multiple plugins"},{"location":"install/","text":"Installation Install from source To install the latest version of the package from source, you can use the following command: make virtualenv source .venv/bin/activate make install","title":"Installation"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#install-from-source","text":"To install the latest version of the package from source, you can use the following command: make virtualenv source .venv/bin/activate make install","title":"Install from source"},{"location":"license/","text":"License View LICENSE on GitHub","title":"License"},{"location":"license/#license","text":"View LICENSE on GitHub","title":"License"},{"location":"usage/","text":"Usage Simple example In this simple example we will download a PDF file from a DOI. The download function will iterate through all the plugins and try to find the PDF URL for the given DOI. If it finds a plugin that can handle the DOI, it will download the PDF file and save it to the specified output directory. from doi_downloader import doi_downloader as ddl doi = \"10.1038/s41586-020-2649-2\" ddl.download(doi, output_dir=\"downloads\") More examples See Examples for more examples of how to use the doi_downloader package.","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#simple-example","text":"In this simple example we will download a PDF file from a DOI. The download function will iterate through all the plugins and try to find the PDF URL for the given DOI. If it finds a plugin that can handle the DOI, it will download the PDF file and save it to the specified output directory. from doi_downloader import doi_downloader as ddl doi = \"10.1038/s41586-020-2649-2\" ddl.download(doi, output_dir=\"downloads\")","title":"Simple example"},{"location":"usage/#more-examples","text":"See Examples for more examples of how to use the doi_downloader package.","title":"More examples"},{"location":"writing_a_plugin/","text":"Creating a new plugin To extend the functionality of doi_downloader , you can create a new plugin. A plugin is a Python module that implements the Plugin interface. Below is a step-by-step guide to creating a new plugin. Step 1: Create a new Python file Create a new Python file in the plugins or extra_plugins directory. extra_plugins folder if plugins that you do not want to commit to GitHub since the folder is ignored. The name of the file should be descriptive of the plugin's functionality, for example, my_plugin.py . Step 2: Implement the Plugin interface In your new Python file, you need to implement the Plugin interface. This involves creating a class that inherits from Plugin and implementing the required methods. Here is an example: import requests from doi_downloader.plugins import Plugin from doi_downloader import article_dataobject as ado # import ArticleDataObject # Read API keys and other sensitive data from environment variables MY_API_URL = \"https://example.com/{doi}\" class MyPlugin(Plugin): def __new__(self): instance = super(Plugin, self).__new__(self) return instance def test(self): return True def fetch_metadata(self, doi): url = MY_API_URL.format(doi=doi) try: if response.status_code == 200: paper = response.json() title = paper.get(\"title\", \"N/A\") download_link = paper.get(\"downloadUrl\", \"N/A\") data_object = ado.ArticleDataObject(None) data_object.set_title(title) data_object.set_doi(doi) if download_link: data_object.add_pdf_link(download_link) return data_object except requests.exceptions.RequestException as e: print(f\"An error occurred: {e}\") return None def get_pdf_url(self, doi, use_cache=True, ttl=0): metadata = self.fetch_metadata(doi) return metadata.get_pdf_url() if metadata else None The plugin needs to implement two functions: fetch_metadata and get_pdf_url . The fetch_metadata function should return an ArticleDataObject containing the metadata of the article, while the get_pdf_url function should return the URL of the PDF file. fetch_metadata should handle the API request and parse the response to extract the necessary information. Step 3: Loading and testing the plugin The doi_downloader loader module will automtically load all plugin files in the plugins or extra_plugins directory. You can test your plugin by loading your plugin withthis script: from doi_downloader import loader as ld plugins = ld.plugins my_plugin = plugins[\"MyPlugin\"] doi = \"10.1000/xyz123\" # Replace with a valid DOI metadata = my_plugin.fetch_metadata(doi) pdf_url = my_plugin.get_pdf_url(doi) Step 4: Caching results It is advantageous to cache the results of the plugin to avoid making repeated API calls for the same DOI. This feature needs to be implemented as part of the plugin. doi_downloader implements a cache object that can be used to store the results of the plugin. The following example shows how to make use of it: from doi_downloader.plugins import Plugin # Load the cache object from doi_downloader.cache_duckdb import Cache from doi_downloader import article_dataobject as ado class MyPlugin(Plugin): def __new__(self): instance = super(Plugin, self).__new__(self) # Initialize the cache object with a database file and plugin name # A table with the plugin name will be created in the database so that # all plugins can share the same database file. self.cache = Cache(\"database.db\", \"myplugin\") return instance def test(self): return True def fetch_metadata(self, doi): # retrieve metadata from API return None # The get_pdf_url method uses the cache to store and retrieve the PDF URL # for a given DOI. If the URL is found in the cache, it is returned. # ttl (time to live) can be set to control how recent the cached object should be. def get_pdf_url(self, doi, use_cache=True, ttl=0): if use_cache: # Check the cache first cached_data = self.cache.get_cache(doi, ttl=ttl) # If cached data is found, return the PDF link from the cached data if cached_data: data_object = ado.ArticleDataObject.from_json(cached_data) data_object.validate() return data_object.get_pdf_link() # If not found in cache, fetch metadata from the API metadata = self.fetch_metadata(doi) if metadata: # If retrieved metadata is valid, store it in the cache. if use_cache: self.cache.set_cache(doi, metadata.to_json()) return metadata.get_pdf_link() else: return None","title":"Developing new plugins"},{"location":"writing_a_plugin/#creating-a-new-plugin","text":"To extend the functionality of doi_downloader , you can create a new plugin. A plugin is a Python module that implements the Plugin interface. Below is a step-by-step guide to creating a new plugin.","title":"Creating a new plugin"},{"location":"writing_a_plugin/#step-1-create-a-new-python-file","text":"Create a new Python file in the plugins or extra_plugins directory. extra_plugins folder if plugins that you do not want to commit to GitHub since the folder is ignored. The name of the file should be descriptive of the plugin's functionality, for example, my_plugin.py .","title":"Step 1: Create a new Python file"},{"location":"writing_a_plugin/#step-2-implement-the-plugin-interface","text":"In your new Python file, you need to implement the Plugin interface. This involves creating a class that inherits from Plugin and implementing the required methods. Here is an example: import requests from doi_downloader.plugins import Plugin from doi_downloader import article_dataobject as ado # import ArticleDataObject # Read API keys and other sensitive data from environment variables MY_API_URL = \"https://example.com/{doi}\" class MyPlugin(Plugin): def __new__(self): instance = super(Plugin, self).__new__(self) return instance def test(self): return True def fetch_metadata(self, doi): url = MY_API_URL.format(doi=doi) try: if response.status_code == 200: paper = response.json() title = paper.get(\"title\", \"N/A\") download_link = paper.get(\"downloadUrl\", \"N/A\") data_object = ado.ArticleDataObject(None) data_object.set_title(title) data_object.set_doi(doi) if download_link: data_object.add_pdf_link(download_link) return data_object except requests.exceptions.RequestException as e: print(f\"An error occurred: {e}\") return None def get_pdf_url(self, doi, use_cache=True, ttl=0): metadata = self.fetch_metadata(doi) return metadata.get_pdf_url() if metadata else None The plugin needs to implement two functions: fetch_metadata and get_pdf_url . The fetch_metadata function should return an ArticleDataObject containing the metadata of the article, while the get_pdf_url function should return the URL of the PDF file. fetch_metadata should handle the API request and parse the response to extract the necessary information.","title":"Step 2: Implement the Plugin interface"},{"location":"writing_a_plugin/#step-3-loading-and-testing-the-plugin","text":"The doi_downloader loader module will automtically load all plugin files in the plugins or extra_plugins directory. You can test your plugin by loading your plugin withthis script: from doi_downloader import loader as ld plugins = ld.plugins my_plugin = plugins[\"MyPlugin\"] doi = \"10.1000/xyz123\" # Replace with a valid DOI metadata = my_plugin.fetch_metadata(doi) pdf_url = my_plugin.get_pdf_url(doi)","title":"Step 3: Loading and testing the plugin"},{"location":"writing_a_plugin/#step-4-caching-results","text":"It is advantageous to cache the results of the plugin to avoid making repeated API calls for the same DOI. This feature needs to be implemented as part of the plugin. doi_downloader implements a cache object that can be used to store the results of the plugin. The following example shows how to make use of it: from doi_downloader.plugins import Plugin # Load the cache object from doi_downloader.cache_duckdb import Cache from doi_downloader import article_dataobject as ado class MyPlugin(Plugin): def __new__(self): instance = super(Plugin, self).__new__(self) # Initialize the cache object with a database file and plugin name # A table with the plugin name will be created in the database so that # all plugins can share the same database file. self.cache = Cache(\"database.db\", \"myplugin\") return instance def test(self): return True def fetch_metadata(self, doi): # retrieve metadata from API return None # The get_pdf_url method uses the cache to store and retrieve the PDF URL # for a given DOI. If the URL is found in the cache, it is returned. # ttl (time to live) can be set to control how recent the cached object should be. def get_pdf_url(self, doi, use_cache=True, ttl=0): if use_cache: # Check the cache first cached_data = self.cache.get_cache(doi, ttl=ttl) # If cached data is found, return the PDF link from the cached data if cached_data: data_object = ado.ArticleDataObject.from_json(cached_data) data_object.validate() return data_object.get_pdf_link() # If not found in cache, fetch metadata from the API metadata = self.fetch_metadata(doi) if metadata: # If retrieved metadata is valid, store it in the cache. if use_cache: self.cache.set_cache(doi, metadata.to_json()) return metadata.get_pdf_link() else: return None","title":"Step 4: Caching results"}]}